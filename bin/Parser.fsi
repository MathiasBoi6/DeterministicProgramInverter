// Signature file for parser generated by fsyacc
module Parser
type token = 
  | EOF
  | VAR of (string * Column)
  | NUM of (int * Column)
  | DEFINE of (Column)
  | LET of (Column)
  | CASE of (Column)
  | NIL of (Column)
  | RETURN of (Column)
  | MAKE of (Column)
  | DUP of (Column)
  | EQ of (Column)
  | LPAR of (Column)
  | RPAR of (Column)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_VAR
    | TOKEN_NUM
    | TOKEN_DEFINE
    | TOKEN_LET
    | TOKEN_CASE
    | TOKEN_NIL
    | TOKEN_RETURN
    | TOKEN_MAKE
    | TOKEN_DUP
    | TOKEN_EQ
    | TOKEN_LPAR
    | TOKEN_RPAR
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startparseProg
    | NONTERM_parseProg
    | NONTERM_Definitions
    | NONTERM_Nonterminal
    | NONTERM_NamedVar
    | NONTERM_Productions
    | NONTERM_ParameterList
    | NONTERM_MakeNary
    | NONTERM_ProductionList
    | NONTERM_Cases
    | NONTERM_Case
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val parseProg : (FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> FSharp.Text.Lexing.LexBuffer<'cty> -> ( fctSyntaxGrammar ) 
